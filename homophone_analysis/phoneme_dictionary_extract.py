#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#Author: Michael Staehli

import argparse
import typing
from typing import Iterator
from itertools import chain
from collections import Counter, OrderedDict
import string
import pandas as pd

"""
Functions to extract and generate phonetic string representations of files.
"""

def data_formatter(filename) -> Iterator:
    """
    Helper function that formats the lines of MFA pronunciation dictionary to be
    further processed.
    @return:
    """
    with open(filename, "r", encoding="utf-8") as infile:
        for line in infile:
            line = line.rstrip().split(maxsplit=1)
            line[0] = line[0].lower()
            yield line

def get_dictionary(filename:str) -> dict:
    """
    Method that returns a dictionary with {grapheme string type: [phoneme string type1, ...n]}
    n is limited to 1 due to MFA parameter setting.
    @filename: Path to dictionary file.
    @return:
    """

    # TODO: list as value not needed, because MFA outputs 1 possible representation.
    # Change values to type str in all methods!
    mappings = {}
    for elem in data_formatter(filename):
        mappings[elem[0]] = elem[1]

    # return as sorted OrderedDict, so sequence is the same and
    # analysis easier.
    return OrderedDict(sorted(mappings.items()))

def get_homophone_tuples(dic: dict) -> dict:
    """
    Method that shows multiple mappings between grapheme and phoneme
    strings.
    @dic: dict {type: [phoneme string type1, phoneme string type2]}
    @return: dictionary {phoneme string type: [type1, type2]}
    """
    # Solution by:
    # https://www.geeksforgeeks.org/python-find-keys-with-duplicate-values-in-dictionary/
    rev_dict = {}
    multiples = dict()

    for key, value in dic.items():
        rev_dict.setdefault(value, set()).add(key)

    result = set(chain.from_iterable(
        values for key, values in rev_dict.items()
        if len(values) > 1))
    for r in result:
        for key, value in dic.items():
            if r == key:
                if value not in multiples:
                    multiples[value] = [key]
                else:
                    multiples[value].append(key)
    #return as sorted OrderedDict, so sequence is the same and
    #analysis easier.
    return OrderedDict(sorted(multiples.items()))

def vocab_to_dictionary(vocab_file: str, full_dic: dict, mfa_dic: dict) -> dict:
    """
    Function that takes a .vocab file and searches the types in a full
    phoneme dictionary and a phoneme dictionary generated by MFA.
    @param vocab_file: Path to vocab file. Contains one type per line.
    @param full_dic: Full dic from output function get_dictionary.
    @param mfa_dic: MFA dic from output function get_dictionary.
    @return:
    """
    phon_dic = {}
    with open(vocab_file, "r", encoding="utf-8") as infile:
        for line in infile:
            #type in vocab
            token = line.rstrip()
            if token in full_dic:
                if token not in phon_dic:
                    phon_dic[token] = full_dic[token]
                else:
                    phon_dic[token].update(full_dic[token])
            else:
                if token in mfa_dic:
                    if token not in phon_dic:
                        phon_dic[token] = mfa_dic[token]
                    else:
                        phon_dic[token].update(mfa_dic[token])
                else:
                    phon_dic[token] = "<UNK>"

    return phon_dic

def replace_special_chars(special_char: str):
    """
    Helper function to replace special characters from moses tokenizer.
    @param special_char:
    @return:
    """
    #TODO as list, change search direction and keep mosees tag.
    special_chars = {"&amp;": "&", "&#124;": "|", "&lt;": "<", "&gt;": ">",
                     "&apos;": "'", "&quot;": '"', "&#91;": "[","&#93;": "]" }
    if special_char in special_chars:
        return special_chars[special_char]
    else:
        return None

def grapheme_to_phoneme(pronunciation_dic:dict, input_file: str,  output_file:str):
    """
    Function that takes a test or training file (1 sentence per line)
    and converts graphemes tokens into phoneme tokens.
    @param pronunciation_dic: Contains mapping of grapheme to phoneme tokens.
    @param input_file: training file, 1 sentence per line.
    @param output_file: file containing tokens as phoneme strings.
    <PUNCT: !>: token is punctuation symbol.
    <UNK: abc.com>: token has unknown phonetic representation.
    <PHON: W IY>: phonetized token.
    @return:
    """
    with open(input_file, "r", encoding="utf-8") as infile, open(output_file, "w", encoding="utf-8") as outfile:
        for line in infile:
            line = line.rstrip().split()
            new_line = ""
            # Other option is to use enumerate!
            for i in range(len(line)):
                token = line[i].lower()
                # Write punctuation symbols to file.
                if token in string.punctuation:
                    new_line = new_line + "<PUNCT:{}>".format(token) + " "
                # Look up phoneme representation of words and write to file.
                else:
                    try:
                        if pronunciation_dic[token] == "<UNK>":
                            # Token was tokenized as special char by moses.
                            special_char = replace_special_chars(token)
                            if special_char != None:
                                new_line + "<PUNCT:{}>".format(
                                    special_char) + " "
                            # Token has no phonetic representation.
                            else:
                                new_line = new_line + \
                                       "<UNK:{}>".format(token) + " "
                        else:
                            new_line = new_line + "<PHON:{}>".format(pronunciation_dic[token])+" "
                    # Special characters
                    except KeyError:
                        #Token was tokenized as special char by moses.
                        special_char = replace_special_chars(token)
                        if special_char != None:
                            new_line + "<PUNCT:{}>".format(special_char) + " "
                        # Token has no phonetic representation.
                        else:
                            new_line = new_line + \
                                   "<UNK:{}>".format(
                                       token) + " "
            #Write line and newline char to outfile.
            # [:-1] to avoid writing last whitespace
            outfile.write(new_line[:-1]+"\n")

def get_arpabet() -> list:
    """
    Function that returns arpabet phonemes.
    @return:
    """
    arpabet = ["AA", "AE", "AH", "AO", "AW", "AY", "B", "CH", "D", "DH",
               "EH", "ER", "EY", "F" , "G" , "HH", "IH", "IY", "JH", "K",
               "L", "M" , "N", "NG", "OW", "OY", "P", "R", "S", "SH", "T",
               "TH", "UH", "UW", "V", "W", "Y", "Z", "ZH"]
    return arpabet

def main():
    pass
    # source_test = "/home/user/staehli/master_thesis/homophone_analysis/mfa_input/test.src.lower.en"
    # target_test = "/home/user/staehli/master_thesis/homophone_analysis/mfa_input/result.lower.de"
    #
    # homophones = [hphone for hphones in source_homophones.values() for hphone in hphones]
    # print(homophones)
    #
    # for homophone in homophones:
    #     print_homophone_translations(homophone, source_test, target_test)
    # print_homophone_translations("meat", source_test, target_test)
    # Print sentences that contain homophones and their translation.


    ### OBSERVATIONS ###
    #Characters not recognized by MFA: ! # % & ( ) , . 0 1 2 3 4 5 6 7 8 9 : ; ? @ á ã ♫

    # I could install Levenshtein library to measure distance between
    #types that are not shared between the two dictionaries!

    # Levenshtein distance (match word, check phonemes) to see if difference in vocabulary
    # is due to misheard word or simply different translation?

    # Overlaps in phoneme representation that doesn't show up in grapheme representation would
    # be interesting. Are there any cases?

    #How can I check if the system is better or worse (because of attention)
    # at the beginning or end of a word?

if __name__ == "__main__":
    main()