#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#Author: Michael Staehli

import argparse
import typing
from typing import Iterator
from itertools import chain
from collections import Counter, OrderedDict
import string
import pandas as pd
import re

"""
Functions to extract and generate phonetic string representations of files.
"""

def data_formatter(filename) -> Iterator:
    """
    Helper function that formats the lines of MFA pronunciation dictionary to be
    further processed.
    @return:
    """
    with open(filename, "r", encoding="utf-8") as infile:
        for line in infile:
            line = line.rstrip().split(maxsplit=1)
            line[0] = line[0].lower()
            yield line

def token_iter(filename) -> Iterator:
    """
    Helper function that yields line from vocabulary or training file.
    @param filename: Path to filename
    @return:
    """
    with open(filename, "r", encoding="utf-8") as infile:
        for line in infile:
            line = line.rstrip()
            #Line is phrase or sentence.
            if " " in line:
                line = line.split()
                for token in line:
                    yield token
            #Line is single token
            else:
                yield line

def get_dictionary(filename:str) -> dict:
    """
    Method that returns a dictionary with {grapheme string type: [phoneme string type1, ...n]}
    n is limited to 1 due to MFA parameter setting.
    @filename: Path to dictionary file.
    @return:
    """

    # TODO: list as value not needed, because MFA outputs 1 possible representation.
    # Change values to type str in all methods!
    mappings = {}
    for elem in data_formatter(filename):
        #Insert phoneme boundary tag.
        mappings[elem[0]] = elem[1].replace(" ", "<pb>")

    # return as sorted OrderedDict, so sequence is the same and
    # analysis easier.
    return OrderedDict(sorted(mappings.items()))

def get_homophone_tuples(dic: dict) -> dict:
    """
    Method that shows multiple mappings between grapheme and phoneme
    strings.
    @dic: dict {type: [phoneme string type1, phoneme string type2]}
    @return: dictionary {phoneme string type: [type1, type2]}
    """
    # Solution by:
    # https://www.geeksforgeeks.org/python-program-to-swap-keys-and-values-in-dictionary/
    new_dict = OrderedDict()

    for key, value in dic.items():
        if value in new_dict:
            new_dict[value].append(key)
        else:
            new_dict[value] = [key]

    # return as sorted OrderedDict, so sequence is the same and
    # analysis easier.
    return new_dict

def vocab_to_dictionary(vocab_file: str, full_dic: dict, *args) -> dict:
    """
    Function that takes a .vocab file and searches the types in a full
    phoneme dictionary and a phoneme dictionary generated by MFA.
    @param vocab_file: Path to vocab file. Contains one type per line.
    @param full_dic: Full dic from output function get_dictionary.
    @param args: Additional MFA dic from output function get_dictionary.
    @return:
    """

    phon_dic = {}
    for token in token_iter(vocab_file):
        #type in vocab
        if token in full_dic:
            if token not in phon_dic:
                # Insert phoneme boundary tag.
                phon_dic[token] = full_dic[token].replace(" ", "<pb>")
        else:
            #Additional phonetic dictionary.
            if args:
                mfa_dic = args[0]
                if token in mfa_dic:
                    if token not in phon_dic:
                        # Insert phoneme boundary tag.
                        phon_dic[token] = mfa_dic[token].replace(" ", "<pb>")
                else:
                    phon_dic[token] = "<UNK>"
    return phon_dic

def grapheme_to_phoneme(pronunciation_dic:dict, input_file: str,  output_file:str):
    """
    Function that takes a test or training file (1 sentence per line)
    and converts graphemes tokens into phoneme tokens.
    @param pronunciation_dic: Contains mapping of grapheme to phoneme tokens.
    @param input_file: training file, 1 sentence per line.
    @param output_file: file containing tokens as phoneme strings.
    <PUNCT: !>: token is punctuation symbol.
    <UNK: abc.com>: token has unknown phonetic representation.
    <PHON: W IY>: phonetized token.
    @return:
    """
    with open(input_file, "r", encoding="utf-8") as infile, open(output_file, "w", encoding="utf-8") as outfile:
        for line in infile:
            line = line.rstrip().split()
            #Add tokens to phonetized line.
            new_line = ""
            # Other option is to use enumerate!
            for token in line:
                # Add punctuation symbols to file.
                if token.lower() in string.punctuation:
                    new_line = new_line + "<PUNCT:{}>".format(token) + " "
                # Look up phoneme representation of words and write to file.
                else:
                    try:
                        new_line = new_line + "<PHON:{}>".format(pronunciation_dic[token.lower()])+" "
                    except KeyError:
                        # Token has no phonetic representation.
                        new_line = new_line + \
                                   "<UNK:{}>".format(
                                       token) + " "
            #Write line and newline char to outfile.
            # [:-1] to avoid writing last whitespace
            outfile.write(new_line[:-1]+"\n")

def get_arpabet() -> list:
    """
    Function that returns arpabet phonemes.
    @return:
    """
    arpabet = ["AA", "AE", "AH", "AO", "AW", "AY", "B", "CH", "D", "DH",
               "EH", "ER", "EY", "F" , "G" , "HH", "IH", "IY", "JH", "K",
               "L", "M" , "N", "NG", "OW", "OY", "P", "R", "S", "SH", "T",
               "TH", "UH", "UW", "V", "W", "Y", "Z", "ZH"]
    return arpabet

def main():
    pass
    # source_test = "/home/user/staehli/master_thesis/homophone_analysis/mfa_input/test.src.lower.en"
    # target_test = "/home/user/staehli/master_thesis/homophone_analysis/mfa_input/result.lower.de"
    #
    # homophones = [hphone for hphones in source_homophones.values() for hphone in hphones]
    # print(homophones)
    #
    # for homophone in homophones:
    #     print_homophone_translations(homophone, source_test, target_test)
    # print_homophone_translations("meat", source_test, target_test)
    # Print sentences that contain homophones and their translation.


    ### OBSERVATIONS ###
    #Characters not recognized by MFA: ! # % & ( ) , . 0 1 2 3 4 5 6 7 8 9 : ; ? @ á ã ♫

    # I could install Levenshtein library to measure distance between
    #types that are not shared between the two dictionaries!

    # Levenshtein distance (match word, check phonemes) to see if difference in vocabulary
    # is due to misheard word or simply different translation?

    # Overlaps in phoneme representation that doesn't show up in grapheme representation would
    # be interesting. Are there any cases?

    #How can I check if the system is better or worse (because of attention)
    # at the beginning or end of a word?

if __name__ == "__main__":
    main()